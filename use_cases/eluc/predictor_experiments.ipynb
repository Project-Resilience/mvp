{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import regionmask\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from joblib import dump, load\n",
    "\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAND_FEATURES = ['c3ann', 'c3nfx', 'c3per','c4ann', 'c4per',\n",
    " 'pastr', 'primf', 'primn', 'range', 'secdf', 'secdn', 'urban']\n",
    "\n",
    "LAND_DIFF_FEATURES = ['c3ann_diff', 'c3nfx_diff', 'c3per_diff','c4ann_diff', 'c4per_diff',\n",
    " 'pastr_diff', 'primf_diff', 'primn_diff', 'range_diff', 'secdf_diff', 'secdn_diff', 'urban_diff']\n",
    "\n",
    "# FEATURES = LAND_FEATURES + [\"cell_area\"]\n",
    "FEATURES = LAND_DIFF_FEATURES\n",
    "LABEL = 'ELUC'\n",
    "\n",
    "TEST_YEAR = 2012\n",
    "\n",
    "AREAS = [\"EU\", \"SA\", \"US\", \"ALL\"]\n",
    "MODELS = AREAS + [\"ENS\"]\n",
    "# Great Britain, France, Germany, Netherlands, Belgium, Switzerland, Ireland\n",
    "EU_COUNTRIES = [\"GB\", \"FR\", \"DE\", \"NL\", \"BE\", \"CH\", \"IE\"]\n",
    "# [\"Brazil\", \"Bolivia\", \"Paraguay\", \"Peru\", \"Ecuador\", \"Colombia\", \"Venezuela\", \"Guyana\", \"Suriname\", \"Uruguay\", \"Argentina\", \"Chile\"]\n",
    "SA_COUNTRIES = [\"BR\", \"BO\", \"PY\", \"PE\", \"EC\", \"CO\", \"VE\", \"GY\", \"SR\", \"UY\", \"AR\", \"CL\"]\n",
    "US_COUNTRIES = [\"US\"]\n",
    "\n",
    "\n",
    "DATA_FILE_PATH = \"../../data/merged_aggregated_dataset_1850_2022.zarr.zip\"\n",
    "UPDATE_FILE_PATH = \"../../data/BLUE_LUH2-GCB2022_ELUC-committed_gridded_net_1850-2021.nc\"\n",
    "\n",
    "# The country codes are weird in regionmask\n",
    "MANUAL_MAP = {\n",
    "    \"INDO\": 360,\n",
    "    \"DRC\": 180,\n",
    "    \"RUS\": 643,\n",
    "    \"N\": 578,\n",
    "    \"F\": 250,\n",
    "    \"J\": 388,\n",
    "    \"NA\": 516,\n",
    "    \"PAL\": 275,\n",
    "    \"J\": 400,\n",
    "    \"IRQ\": 368,\n",
    "    \"IND\": 356,\n",
    "    \"IRN\": 364,\n",
    "    \"SYR\": 760,\n",
    "    \"ARM\": 51,\n",
    "    \"S\": 752,\n",
    "    \"A\": 36,\n",
    "    \"EST\": 233,\n",
    "    \"D\": 276,\n",
    "    \"L\": 442,\n",
    "    \"B\": 56,\n",
    "    \"P\": 620,\n",
    "    \"E\": 724,\n",
    "    \"IRL\": 372,\n",
    "    \"I\": 380,\n",
    "    \"SLO\": 705,\n",
    "    \"FIN\": 246,\n",
    "    \"J\": 392,\n",
    "    \"BiH\": 70,\n",
    "    \"NM\": 807,\n",
    "    \"KO\": 383,\n",
    "    \"SS\": 728\n",
    "}\n",
    "\n",
    "countries = regionmask.defined_regions.natural_earth_v5_0_0.countries_110\n",
    "countries_df = countries.to_dataframe()\n",
    "\n",
    "codes_df = pd.read_csv(\"../mvp/data/gcb/conversion/codes.csv\")\n",
    "\n",
    "# Replace all the bad codes with their real ones\n",
    "for i in range(len(countries_df)):\n",
    "    old_abbrev = countries_df.iloc[i][\"abbrevs\"]\n",
    "    if old_abbrev in MANUAL_MAP.keys() and MANUAL_MAP[old_abbrev] in codes_df[\"Numeric code\"].unique():\n",
    "        countries_df.iloc[i][\"abbrevs\"] = codes_df[codes_df[\"Numeric code\"] == MANUAL_MAP[old_abbrev]][\"Alpha-2 code\"].iloc[0]\n",
    "\n",
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(path, update_path):\n",
    "    raw = xr.open_zarr(path, consolidated=True)\n",
    "\n",
    "    # Get updated ELUC\n",
    "    if update_path:\n",
    "        eluc = xr.open_dataset(update_path)\n",
    "        raw = raw.drop_vars([\"ELUC\", \"cell_area\"])\n",
    "        raw = raw.merge(eluc)\n",
    "\n",
    "    # Shift actions back a year\n",
    "    raw[LAND_DIFF_FEATURES] = raw[LAND_DIFF_FEATURES].shift(time=-1)\n",
    "\n",
    "    # Old time shifting\n",
    "    # raw['ELUC'] = raw['ELUC'].shift(time=1)\n",
    "    # raw['ELUC_diff'] = raw['ELUC_diff'].shift(time=1)\n",
    "    # raw['time'] = raw.time - 1\n",
    "    # assert(list(np.unique(raw.time)) == list(range(1849, 2022)))\n",
    "    # mask = raw[\"ELUC_diff\"].isnull().compute()\n",
    "    # raw = raw.where(~mask, drop=True)\n",
    "\n",
    "    country_mask = regionmask.defined_regions.natural_earth_v5_0_0.countries_110.mask(raw)\n",
    "    raw[\"country\"] = country_mask\n",
    "    return raw\n",
    "\n",
    "\n",
    "def subset_countries(df, countries):\n",
    "    \"\"\"\n",
    "    Subsets dataframe by country list\n",
    "    \"\"\"\n",
    "    if countries:\n",
    "        idx = countries_df[countries_df[\"abbrevs\"].isin(countries)].index.values\n",
    "        return df[df[\"country\"].isin(idx)].copy()\n",
    "    return df.copy()\n",
    "\n",
    "\n",
    "def da_to_df(da, start_year=None, end_year=None, countries=None):\n",
    "    df = da.to_dataframe()\n",
    "    df = df.dropna()\n",
    "    df = df.reorder_levels([\"time\", \"lat\", \"lon\"]).sort_index()\n",
    "    df['country_name'] = countries_df.loc[df['country'], 'names'].values\n",
    "    if start_year:\n",
    "        df = df.loc[start_year:]\n",
    "    if end_year:\n",
    "        df = df.loc[:end_year]\n",
    "    if countries:\n",
    "        df = subset_countries(df, countries)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n",
      "/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/dask/array/core.py:4830: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  result = blockwise(\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "raw = import_data(DATA_FILE_PATH, UPDATE_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ELUC_diff</th>\n",
       "      <th>c3ann</th>\n",
       "      <th>c3ann_diff</th>\n",
       "      <th>c3nfx</th>\n",
       "      <th>c3nfx_diff</th>\n",
       "      <th>c3per</th>\n",
       "      <th>c3per_diff</th>\n",
       "      <th>c4ann</th>\n",
       "      <th>c4ann_diff</th>\n",
       "      <th>c4per</th>\n",
       "      <th>...</th>\n",
       "      <th>secdf</th>\n",
       "      <th>secdf_diff</th>\n",
       "      <th>secdn</th>\n",
       "      <th>secdn_diff</th>\n",
       "      <th>urban</th>\n",
       "      <th>urban_diff</th>\n",
       "      <th>ELUC</th>\n",
       "      <th>cell_area</th>\n",
       "      <th>country</th>\n",
       "      <th>country_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1851</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">-55.375</th>\n",
       "      <th>-69.375</th>\n",
       "      <td>1.585186e-04</td>\n",
       "      <td>1.529372e-07</td>\n",
       "      <td>-1.466177e-09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012612</td>\n",
       "      <td>1.048539e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.283220e-03</td>\n",
       "      <td>43908.949219</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Chile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-69.125</th>\n",
       "      <td>-1.669832e-09</td>\n",
       "      <td>6.256299e-08</td>\n",
       "      <td>-4.925624e-10</td>\n",
       "      <td>8.209591e-09</td>\n",
       "      <td>-6.463452e-11</td>\n",
       "      <td>1.742937e-08</td>\n",
       "      <td>-1.372218e-10</td>\n",
       "      <td>8.359032e-09</td>\n",
       "      <td>-6.581136e-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>-1.396984e-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.430041e-07</td>\n",
       "      <td>43908.949219</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Chile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-68.875</th>\n",
       "      <td>3.134616e-07</td>\n",
       "      <td>2.541674e-08</td>\n",
       "      <td>3.165289e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-3.637979e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.217266e-06</td>\n",
       "      <td>43908.949219</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Chile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-68.625</th>\n",
       "      <td>-2.126626e-08</td>\n",
       "      <td>6.788947e-08</td>\n",
       "      <td>-7.737526e-10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>5.940819e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.565677e-08</td>\n",
       "      <td>43908.949219</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Chile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-68.375</th>\n",
       "      <td>-8.974894e-09</td>\n",
       "      <td>1.061018e-06</td>\n",
       "      <td>-5.096126e-09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>-3.637979e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.761452e-07</td>\n",
       "      <td>43908.949219</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Chile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ELUC_diff         c3ann    c3ann_diff         c3nfx  \\\n",
       "time lat     lon                                                               \n",
       "1851 -55.375 -69.375  1.585186e-04  1.529372e-07 -1.466177e-09  0.000000e+00   \n",
       "             -69.125 -1.669832e-09  6.256299e-08 -4.925624e-10  8.209591e-09   \n",
       "             -68.875  3.134616e-07  2.541674e-08  3.165289e-08  0.000000e+00   \n",
       "             -68.625 -2.126626e-08  6.788947e-08 -7.737526e-10  0.000000e+00   \n",
       "             -68.375 -8.974894e-09  1.061018e-06 -5.096126e-09  0.000000e+00   \n",
       "\n",
       "                        c3nfx_diff         c3per    c3per_diff         c4ann  \\\n",
       "time lat     lon                                                               \n",
       "1851 -55.375 -69.375  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "             -69.125 -6.463452e-11  1.742937e-08 -1.372218e-10  8.359032e-09   \n",
       "             -68.875  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "             -68.625  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "             -68.375  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "\n",
       "                        c4ann_diff  c4per  ...     secdf    secdf_diff  \\\n",
       "time lat     lon                           ...                           \n",
       "1851 -55.375 -69.375  0.000000e+00    0.0  ...  0.012612  1.048539e-04   \n",
       "             -69.125 -6.581136e-11    0.0  ...  0.001253 -1.396984e-09   \n",
       "             -68.875  0.000000e+00    0.0  ...  0.000000  0.000000e+00   \n",
       "             -68.625  0.000000e+00    0.0  ...  0.000000  0.000000e+00   \n",
       "             -68.375  0.000000e+00    0.0  ...  0.000000  0.000000e+00   \n",
       "\n",
       "                         secdn    secdn_diff  urban  urban_diff          ELUC  \\\n",
       "time lat     lon                                                                \n",
       "1851 -55.375 -69.375  0.000000  0.000000e+00    0.0         0.0  4.283220e-03   \n",
       "             -69.125  0.000000  0.000000e+00    0.0         0.0 -3.430041e-07   \n",
       "             -68.875  0.000034 -3.637979e-12    0.0         0.0  3.217266e-06   \n",
       "             -68.625  0.000038  5.940819e-09    0.0         0.0 -7.565677e-08   \n",
       "             -68.375  0.000044 -3.637979e-12    0.0         0.0 -3.761452e-07   \n",
       "\n",
       "                         cell_area  country  country_name  \n",
       "time lat     lon                                           \n",
       "1851 -55.375 -69.375  43908.949219     10.0         Chile  \n",
       "             -69.125  43908.949219     10.0         Chile  \n",
       "             -68.875  43908.949219     10.0         Chile  \n",
       "             -68.625  43908.949219     10.0         Chile  \n",
       "             -68.375  43908.949219     10.0         Chile  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = da_to_df(raw)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df[\"ELUC\"], bins=[-0.02, -0.01, 0, 0.01, 0.02], density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EU': ['GB', 'FR', 'DE', 'NL', 'BE', 'CH', 'IE'], 'SA': ['BR', 'BO', 'PY', 'PE', 'EC', 'CO', 'VE', 'GY', 'SR', 'UY', 'AR', 'CL'], 'US': ['US'], 'ALL': None}\n"
     ]
    }
   ],
   "source": [
    "countries_dict = dict(zip(AREAS, [EU_COUNTRIES, SA_COUNTRIES, US_COUNTRIES, None]))\n",
    "print(countries_dict)\n",
    "\n",
    "data_dict = dict()\n",
    "for area in countries_dict.keys():\n",
    "    data_dict[area] = subset_countries(df, countries_dict[area])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperPredictor():\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        for model in self.models:\n",
    "            preds.append(model.predict(X))\n",
    "        preds_np = np.stack(preds, axis=0)\n",
    "        avgs = preds_np.mean(axis=0)\n",
    "        return avgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet():\n",
    "\n",
    "    class CustomDS(Dataset):\n",
    "        def __init__(self, X_train, y_train):\n",
    "            super().__init__()\n",
    "            self.X = torch.tensor(X_train.to_numpy()).to(device)\n",
    "            self.y = torch.tensor(y_train.to_numpy()).to(device)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.X)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "    def __init__(self, in_size, hidden_size): \n",
    "        # Model\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_size, hidden_size),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "        self.model.to(device)\n",
    "\n",
    "    def fit(self, X_train, y_train, test=None, epochs=10, batch_size=2048, lr=1e-2, momentum=0.9, weight_decay=1e-3):\n",
    "        train_ds = self.CustomDS(X_train, y_train)\n",
    "        train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "\n",
    "        if test:\n",
    "            X_test, y_test = test\n",
    "            test_ds = self.CustomDS(X_test, y_test)\n",
    "            test_dl = DataLoader(test_ds, batch_size, shuffle=True)\n",
    "\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        loss_fn = torch.nn.L1Loss()\n",
    "        # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 3, 0.1)\n",
    "\n",
    "        writer = SummaryWriter(f\"runs/{len(os.listdir('runs'))}\")\n",
    "\n",
    "        \n",
    "        step = 0\n",
    "        test_step = 0\n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            for X, y in tqdm(train_dl):\n",
    "                optimizer.zero_grad()\n",
    "                out = self.model(X).squeeze()\n",
    "                loss = loss_fn(out, y)\n",
    "                writer.add_scalar(\"loss\", loss.item(), step)\n",
    "                step += 1\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            # scheduler.step()\n",
    "\n",
    "            if test_dl:\n",
    "                total = 0\n",
    "                self.model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for X, y in tqdm(test_dl):\n",
    "                        out = self.model(X).squeeze()\n",
    "                        loss = loss_fn(out, y)\n",
    "                        writer.add_scalar(\"test_loss\", loss.item(), test_step)\n",
    "                        test_step += 1\n",
    "                        \n",
    "                        total += loss.item() * y.shape[0]\n",
    "\n",
    "                print(f\"epoch {epoch} mae {total / len(test_ds)}\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X = torch.tensor(X_test.to_numpy()).to(device)\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            return self.model(X).squeeze().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/162 [00:00<?, ?it/s]/Users/964840/anaconda3/envs/leaf/lib/python3.10/site-packages/torch/autograd/__init__.py:204: UserWarning: The operator 'aten::sgn.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "100%|██████████| 162/162 [00:16<00:00,  9.58it/s]\n",
      "100%|██████████| 41/41 [00:03<00:00, 10.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 mae 0.13232546445150428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:14<00:00, 10.95it/s]\n",
      "100%|██████████| 41/41 [00:03<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 mae 0.12238975209845107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:14<00:00, 11.05it/s]\n",
      "100%|██████████| 41/41 [00:03<00:00, 10.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 mae 0.10676416018017366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:14<00:00, 11.00it/s]\n",
      "100%|██████████| 41/41 [00:03<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 mae 0.0922380927267876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:14<00:00, 11.26it/s]\n",
      "100%|██████████| 41/41 [00:03<00:00, 11.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 mae 0.08211208181262213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:14<00:00, 10.88it/s]\n",
      "100%|██████████| 41/41 [00:03<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 mae 0.07116248473601375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:14<00:00, 10.82it/s]\n",
      "100%|██████████| 41/41 [00:03<00:00, 10.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 mae 0.07011499760305753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:15<00:00, 10.58it/s]\n",
      "100%|██████████| 41/41 [00:03<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 mae 0.0656016996529807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:15<00:00, 10.58it/s]\n",
      "100%|██████████| 41/41 [00:03<00:00, 11.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 mae 0.06554782893204443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:15<00:00, 10.60it/s]\n",
      "100%|██████████| 41/41 [00:03<00:00, 10.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 mae 0.06364993655999594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Ideas:\n",
    "# Play with test year cutoff\n",
    "# Test set sample - does the distribution change a lot over time?\n",
    "# Could try different sizes\n",
    "# Learning rate scheduler\n",
    "time_test = False\n",
    "nn_feats = LAND_FEATURES + LAND_DIFF_FEATURES\n",
    "net = NeuralNet(len(nn_feats),\n",
    "                len(nn_feats) // 2, \n",
    "                epochs=10)\n",
    "\n",
    "net_data = data_dict[\"ALL\"].sample(frac=0.01, random_state=42)\n",
    "if time_test:\n",
    "    train, test = net_data.loc[:2012], net_data.loc[2012:]\n",
    "else:\n",
    "    train, test = train_test_split(net_data, test_size=0.2, random_state=42, shuffle=True)\n",
    "    \n",
    "X_train, y_train = train[nn_feats], train[\"ELUC\"]\n",
    "X_test, y_test = test[nn_feats], test[\"ELUC\"]\n",
    "\n",
    "net.fit(X_train, y_train, (X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sk(df, model_type, features, params={}, test_year=TEST_YEAR, save=False):\n",
    "    \"\"\"\n",
    "    Trains linear regression model\n",
    "    \"\"\"\n",
    "    train = df.loc[:test_year]\n",
    "    test = df.loc[test_year:]\n",
    "    X_train = train[features]\n",
    "    y_train = train[LABEL]\n",
    "    X_test = test[features]\n",
    "    y_test = test[LABEL]\n",
    "\n",
    "    if model_type == \"linreg\":\n",
    "        model = LinearRegression(n_jobs=-1, **params)\n",
    "    elif model_type == \"forest\":\n",
    "        model = RandomForestRegressor(n_jobs=-1, **params)\n",
    "    else:\n",
    "        model = NeuralNet(len(features), (len(features) + 1) // 2, batch_size=4096, epochs=2, **params)\n",
    "\n",
    "    s = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    e = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    if save:\n",
    "        dump(model, f\"saved/{save}.joblib\")\n",
    "\n",
    "    return model, mae, e - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([437886, 25])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:19<00:00,  5.35it/s]\n",
      "100%|██████████| 107/107 [00:18<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU : 0.4076438844203949 : 38.998635053634644\n",
      "torch.Size([3918942, 25])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [02:49<00:00,  5.64it/s]\n",
      "100%|██████████| 957/957 [02:53<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA : 0.2520342469215393 : 343.4472460746765\n",
      "torch.Size([2846988, 25])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 696/696 [02:04<00:00,  5.61it/s]\n",
      "100%|██████████| 696/696 [02:06<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US : 0.09549366682767868 : 250.30956411361694\n",
      "torch.Size([39209670, 25])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9573/9573 [29:08<00:00,  5.47it/s]\n",
      "100%|██████████| 9573/9573 [30:13<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL : 0.14587053656578064 : 3566.11097407341\n"
     ]
    }
   ],
   "source": [
    "nn_dict = dict()\n",
    "for area in data_dict.keys():\n",
    "    model, mae, t = train_sk(data_dict[area], \"nn\", LAND_FEATURES + [\"cell_area\"] + LAND_DIFF_FEATURES)\n",
    "    nn_dict[area] = model\n",
    "    print(f\"{area} : {mae} : {t}\")\n",
    "\n",
    "nn_models = list(nn_dict.values())\n",
    "super_nn = SuperPredictor(nn_models)\n",
    "nn_dict[\"ENS\"] = super_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU : 0.03312671184539795 : 0.16405510902404785\n",
      "SA : 0.15485286712646484 : 0.7999930381774902\n",
      "US : 0.03451376035809517 : 0.4849739074707031\n",
      "ALL : 0.07230156660079956 : 10.302732229232788\n"
     ]
    }
   ],
   "source": [
    "linreg_dict = dict()\n",
    "for area in data_dict.keys():\n",
    "    model, mae, t = train_sk(data_dict[area], \"linreg\", LAND_DIFF_FEATURES, save=f\"{area}-linreg\")\n",
    "    linreg_dict[area] = model\n",
    "    print(f\"{area} : {mae} : {t}\")\n",
    "\n",
    "linreg_models = list(linreg_dict.values())\n",
    "super_linreg = SuperPredictor(linreg_models)\n",
    "linreg_dict[\"ENS\"] = super_linreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU : 0.03122097690954875 : 17.572288990020752\n",
      "SA : 0.07220671190398535 : 311.5672650337219\n",
      "US : 0.019661567357595097 : 114.83990669250488\n",
      "ALL : 0.054929612174459574 : 262.7167739868164\n"
     ]
    }
   ],
   "source": [
    "forest_dict = dict()\n",
    "for area in data_dict.keys():\n",
    "    start_year = 1982\n",
    "    if area == \"ALL\":\n",
    "        start_year = 2010\n",
    "    model, mae, t = train_sk(data_dict[area].loc[start_year:], \"forest\", LAND_FEATURES + [\"cell_area\"] + LAND_DIFF_FEATURES, save=f\"{area}-forest\")\n",
    "    forest_dict[area] = model\n",
    "    print(f\"{area} : {mae} : {t}\")\n",
    "\n",
    "forest_models = list(forest_dict.values())\n",
    "super_forest = SuperPredictor(forest_models)\n",
    "forest_dict[\"ENS\"] = super_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sk(model, df, features, test_year=TEST_YEAR, end_year=None):\n",
    "    if not test_year:\n",
    "        test = df\n",
    "    else:\n",
    "        test = df.loc[test_year:]\n",
    "    X_test = test[features]\n",
    "    y_test = test[LABEL]\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    return mae\n",
    "\n",
    "def acc_graph(linreg_dict, forest_dict, data_dict, test_year=TEST_YEAR, save=None):\n",
    "    for area in AREAS:\n",
    "        linreg_maes = []\n",
    "        forest_maes = []\n",
    "        for t in range(test_year, 2022):\n",
    "            linreg_mae = eval_sk(linreg_dict[area], data_dict[area].loc[t], LAND_DIFF_FEATURES, test_year=None)\n",
    "            forest_mae = eval_sk(forest_dict[area], data_dict[area].loc[t], LAND_FEATURES + [\"cell_area\"] + LAND_DIFF_FEATURES, test_year=None)\n",
    "            linreg_maes.append(linreg_mae)\n",
    "            forest_maes.append(forest_mae)\n",
    "\n",
    "        plt.plot(range(TEST_YEAR, 2022), linreg_maes, label=f\"{area} linreg\", marker=\"o\")\n",
    "        plt.plot(range(TEST_YEAR, 2022), forest_maes, label=f\"{area} forest\", marker=\"x\")\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim([0, 0.25])\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.grid()\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"MAE\")\n",
    "    plt.title(\"MAE over Time for All Models\")\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(save, bbox_inches=\"tight\", transparent=False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EU', 'SA', 'US', 'ALL', 'ENS']\n",
      "[[0.03312671 0.25698057 0.17198437 0.22040431]\n",
      " [0.14224406 0.15485287 0.06476258 0.11095934]\n",
      " [0.14021051 0.1466895  0.03451376 0.07200481]\n",
      " [0.14098775 0.15198237 0.03655225 0.07230157]\n",
      " [0.10547955 0.16505462 0.06981746 0.10059017]]\n",
      "[[0.03122098 0.23995696 0.11861614 0.22561084]\n",
      " [0.17421035 0.07220671 0.04592406 0.10744972]\n",
      " [0.15534629 0.18813189 0.01966157 0.11396047]\n",
      " [0.09920544 0.08690793 0.02566942 0.05492961]\n",
      " [0.10228721 0.12722926 0.04442375 0.08311628]]\n"
     ]
    }
   ],
   "source": [
    "linreg_grid = np.zeros((len(MODELS), len(AREAS)))\n",
    "forest_grid = np.zeros(linreg_grid.shape)\n",
    "for i in range(len(MODELS)):\n",
    "    model_name = MODELS[i]\n",
    "    for j in range(len(AREAS)):\n",
    "        data_area = AREAS[j]\n",
    "        linreg_mae = eval_sk(linreg_dict[model_name], data_dict[data_area], LAND_DIFF_FEATURES)\n",
    "        forest_mae = eval_sk(forest_dict[model_name], data_dict[data_area], LAND_FEATURES + [\"cell_area\"] + LAND_DIFF_FEATURES)\n",
    "\n",
    "        linreg_grid[i, j] = linreg_mae\n",
    "        forest_grid[i, j] = forest_mae\n",
    "\n",
    "print(MODELS)\n",
    "print(linreg_grid)\n",
    "print(forest_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462213\n",
      "4136661\n",
      "3005154\n",
      "41387985\n"
     ]
    }
   ],
   "source": [
    "for area in AREAS:\n",
    "    print(len(data_dict[area]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0312 & 0.24 & 0.1186 & 0.2256 & \n",
      "0.1742 & 0.0722 & 0.0459 & 0.1074 & \n",
      "0.1553 & 0.1881 & 0.0197 & 0.114 & \n",
      "0.0992 & 0.0869 & 0.0257 & 0.0549 & \n",
      "0.1023 & 0.1272 & 0.0444 & 0.0831 & \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(forest_grid)):\n",
    "    line = \"\"\n",
    "    for j in range(len(forest_grid[0])):\n",
    "        line += f\"{round(forest_grid[i, j], 4)} & \"\n",
    "\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_graph(linreg_dict, forest_dict, data_dict, save=\"saved/mae.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment on extreme ELUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77432704\n",
      "0.6465967089249522\n"
     ]
    }
   ],
   "source": [
    "mean = df[\"ELUC\"].mean()\n",
    "std = df[\"ELUC\"].std()\n",
    "extreme_df = df[(df[\"ELUC\"] >= mean + std * 2) | (df[\"ELUC\"] <= mean - std * 2)]\n",
    "print(eval_sk(linreg_dict[\"ALL\"], extreme_df, LAND_DIFF_FEATURES))\n",
    "print(eval_sk(forest_dict[\"ALL\"], extreme_df, LAND_FEATURES + [\"cell_area\"] + LAND_DIFF_FEATURES))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leaf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
